
# 海量数据分流处理技术
## 划分方法—最基本的海量技术思想
- 传统Hash，最基本的划分方法  
  - 如何将大数据、流量均分到N台服务器  
  - 找到合理的key，hash（key）尽量分布均匀  
  - hash(key)mod N == 0 分到 第0台，  
  - hash(key)mod N == i 分到 第i台  
  - hash(key)mod N == N-1 分到 第N-1台  
![image](269BCF9E6E6744758A838ADAC8FCFD73)  
上图为一个非常简单的负载均衡原理：来一个请求，通过Hash算法，然后将请求随机发给一台服务器。  
Hash算法：会给每个请求分配一个随机值，而随机值是以时间为种子random的。以保证分配的均匀。随机值通过Hash算法，得到不同的“桶号”，再将其发给对应的服务器。  
但是，如果在分配请求时，某一台服务器宕机，那么分配到这台服务器上的请求就无法被处理。	解决的方法：一致性Hash方法。  
- 随机划分
- 一致性Hash：支持动态增长，更高级的划分方法  
![image](12A8B10FE0F2464EADBDAB443F0F9255)  
一致性哈希算法设计目标是为了解决因特网中的热点(Hotspot)问题  
## 分而治之—最基本的海量技术思想
- 大数据量——按数据划分
  - 早期搜索引擎中的网页存储系统，单机存储数千万网页，几十亿的网页需要通过几百台单机服务器存储，url（网址）为key
  - 分布式文件系统，按block(64-256M)来划分组织文件
- 大流量——按流量划分
  - 覆盖的大流量互联网服务
  - 南方流量分到电信机房，北方流量分到联通机房
  - 搜索引擎将query作为key来分流
- 大计算——按输入数据，划分计算任务
  - Map Reduce 按输入数据来划分
## 云计算技术难点  
- 单机系统变为分布式集群系统
- 稳定性和容错能力
- 数据一致性
  - 弱一致
  - 强一致  

![image](C9353074F98B43009C2D18351D646CC0)   
> 如图，有一个机器，上面有一个变量A=5。有两个用户，用户B，用户C。两个用户都想对变量进行操作“A++”。  
首先，用户B将变量A=5读下来，然后进行计算，得到A=6。再将其写回去。机器里就会存有变量A=6。接着用户C进行同样操作，机器内得到变量A=7。  
但是，如果在用户B将计算完的变量A写回机器前（此时A=6），用户C提前发出请求，将变量A读下来（此时A=5），也进行操作，得到A=6。  
在用户B将变量A写回机器后（此时A=6），用户C也将变量A写回机器（此时A=6）。这样得到的最后结果就是错误的  
这是因为用户B和用户C没有遵守顺序一致性。用户B读到的A=5是脏数据（正常应该是A=6），再怎么计算也是错误的。  

强一致性与弱一致性：  
	比如说在整个集群上有很多节点，对于从节点，每个节点上提供个服务都是一样的，每个节点上储存的数据都是一致的。  
强一致性：在往这些节点上写数据时，只有全部节点都被写入数据后，才能提供服务。  
弱一致性：每个节点只要被写入数据，就能提供服务。（能更快地提供服务）  

- 难点:
  - 任何消息存在丢失的可能
  - 任何单机存在故障的风险


 










